use package core


//
// Variable
//
// TODO(Brendan Hansen): Document this better
Variable :: struct { value, delta: f32; }

//
// General purpose Multi-Layer Perceptron (MLP)
//

NeuralNet :: struct {
    layers : [] Layer;

    // CLEANUP(Brendan Hansen): Move all allocators to core.alloc,
    // so the nesting isn't nearly as terrible.
    layer_arena : alloc.arena.ArenaState;

    make :: (layer_sizes: ..i32) -> NeuralNet {
        net : NeuralNet;

        // BUGFIX: It should be possible to omit 'NeuralNet.' here because
        // init is defined in the same scope. This is happening because at
        // parse time, these functions are not being entered in the correct
        // scope and thus are not resolving the correct symbols.
        NeuralNet.init(^net, layer_sizes.count);

        layer_allocator := alloc.arena.make_allocator(^net.layer_arena);

        Layer.init(^net.layers[0], layer_sizes[0], 0, allocator = layer_allocator);
        for i: 1 .. net.layers.count {
            Layer.init(^net.layers[i], layer_sizes[i], layer_sizes[i - 1], allocator = layer_allocator);
        }

        return net;
    }

    init :: (use nn: ^NeuralNet, layer_count: u32) {
        layer_arena      = alloc.arena.make(context.allocator, 64 * 1024 * 1024); // 64 MiB
        layer_allocator := alloc.arena.make_allocator(^layer_arena);

        layers = memory.make_slice(Layer, layer_count, allocator = layer_allocator);
    }

    free :: (use nn: ^NeuralNet) {
        alloc.arena.free(^layer_arena);
    }

    forward :: (use nn: ^NeuralNet, input: [] f32) {
        assert(input.count == layers[0].neurons.count, "Input does not have the same size as the first layer.");

        for i: input.count do layers[0].neurons[i] = input[i];

        for i: 1 .. layers.count {
            Layer.forward(^layers[i], ^layers[i - 1]);
        }
    }

    backward :: (use nn: ^NeuralNet, expected_output: [] f32, criterion: Criterion) {
        assert(layers[layers.count - 1].neurons.count == expected_output.count,
                "Expected output does not have the same size as the last layer.");

        // NOTE(Brendan Hansen):
        // Iterating backwards through the layers (hence the name "back propagation")
        // The reason this is necessary is because we need to know the derivatives of
        // neurons in the next layer to compute the derivatives of the current layers
        // neurons. This is what makes this algorithm not exponentially slow.
        while i := layers.count - 1; i >= 1 {
            defer i -= 1;
            
            // NOTE(Brendan Hansen):
            // For every neuron, we need to calculate its corresponding "delta", which is
            // kind of an ambiguous term here. It specifically means the partial derivative
            // of the the loss with respect to the weighted sum of the previous layers
            // neurons, plus a bias.
            
            // The last layer has its derivative computed special, since it needs to capture
            // the derivative of the criterion function.
            if i == layers.count - 1 {
                criterion.compute_deltas(layers[i].deltas, layers[i].neurons, expected_output);
                
                // NOTE(Brendan Hansen): 
                // Here we multiply by the derivative of the activation function for each neuron.
                // This is done in the layer_backward function, but since that isn't called for the
                // last layer, it is necessary to do it here.
                for j: layers[i].deltas.count {
                    d_sigmoid_value := layers[i].activation.backward(layers[i].neurons[j], layers[i].pre_activation_neurons[j]);
                    layers[i].deltas[j] *= d_sigmoid_value;
                }
                
            } else {
                Layer.backward(^layers[i], ^layers[i + 1]);
            }
        }
        
        // NOTE(Brendan Hansen): 
        // Once all the deltas are computed, we can use them to compute the actual
        // derivatives and update the biases and weights.
        // This part is responsible for optimization, and can easily be swapped out.
        for i: 1 .. layers.count {
            for j: layers[i].neurons.count {
                if layers[i].use_bias {
                    layers[i].biases[j].delta += layers[i].deltas[j];
                }

                prev_layer_count := layers[i - 1].neurons.count;
                for k: prev_layer_count {
                    layers[i].weights[j * prev_layer_count + k].delta += layers[i].deltas[j] * layers[i - 1].neurons[k];
                }
            }
        }
    }

    get_output :: (use nn: ^NeuralNet) -> [] f32 {
        return layers[layers.count - 1].neurons;
    }

    // :MNISTSpecific
    get_prediction :: (use nn: ^NeuralNet) -> i32 {
        output := get_output(nn);

        greatest_idx := 0;
        for i: output.count do if output[i] > output[greatest_idx] do greatest_idx = i;

        return greatest_idx;
    }

    get_loss :: (use nn: ^NeuralNet, expected_output: [] f32, criterion: Criterion) -> f32 {
        return criterion.compute_loss(layers[layers.count - 1].neurons, expected_output);
    }

    supply_parameters :: (use nn: ^NeuralNet, optimizer: ^Optimizer) {
        for ^layer: layers {
            if layer.biases.data != null  do array.push(^optimizer.variable_arrays, ^layer.biases);
            if layer.weights.data != null do array.push(^optimizer.variable_arrays, ^layer.weights);
        }
    }
}


Layer :: struct {
    use_bias   : bool;
    is_input   : bool;
    activation : ActivationFunction;

    biases  : [] Variable;
    weights : [] Variable;

    neurons                : [] f32;
    pre_activation_neurons : [] f32;

    deltas : [] f32;

    init :: (use layer: ^Layer, layer_size: u32, prev_layer_size: u32, allocator := context.allocator, allocate_weights_and_biases := true) {
        neurons = memory.make_slice(f32, layer_size, allocator);
        pre_activation_neurons = memory.make_slice(f32, layer_size, allocator);

        use_bias = true;
        deltas = memory.make_slice(f32, layer_size, allocator);
        activation = sigmoid_activation;

        is_input = (prev_layer_size == 0);

        if !is_input && allocate_weights_and_biases {
            if use_bias {
                biases = memory.make_slice(Variable, layer_size, allocator);
            }
            
            weights = memory.make_slice(Variable, layer_size * prev_layer_size, allocator);

            randomize_weights_and_biases(layer);
        }
    }

    randomize_weights_and_biases :: (use layer: ^Layer) {
        for ^weight: weights {
            weight.value = cast(f32) random.float(-0.5f, 0.5f);
        }

        if use_bias {
            for ^bias: biases do bias.value = cast(f32) random.float(-0.5f, 0.5f);
        }
    }

    forward :: (use layer: ^Layer, prev_layer: ^Layer) {
        for i: neurons.count {
            neuron: f32 = 0;
            if use_bias do neuron = biases[i].value;

            for j: prev_layer.neurons.count {
                neuron += prev_layer.neurons[j] * weights[i * prev_layer.neurons.count + j].value;
            }

            pre_activation_neurons[i] = neuron;
            neurons[i] = activation.forward(neuron);
        }
    }

    backward :: (use layer: ^Layer, next_layer: ^Layer) {
        for j: neurons.count {
            d_neuron: f32 = 0;
            for k: next_layer.neurons.count {
                d_neuron += next_layer.deltas[k] * next_layer.weights[k * neurons.count + j].value;
            }
            
            d_sigmoid_value := activation.backward(neurons[j], pre_activation_neurons[j]);
            
            deltas[j] = d_neuron * d_sigmoid_value;
        }
    }
}


Onyx_NN_Magic_Number := 0x4E4E584F

neural_net_save :: (use nn: ^NeuralNet, filename: str) {
    err, output_file := io.open(filename, io.OpenMode.Write);
    assert(err == io.Error.None, "Failed to open neural net save file for writing.");
    defer io.stream_close(^output_file);

    writer := io.binary_writer_make(^output_file);

    // Magic string
    io.binary_write(^writer, i32, ^Onyx_NN_Magic_Number);

    // Number of layers
    io.binary_write(^writer, i32, ^layers.count);

    for ^layer: layers {
        io.binary_write(^writer, i32, ^layer.neurons.count);

        io.binary_write_byte(^writer, cast(u8) layer.is_input);
        if layer.is_input do continue;

        io.binary_write_byte(^writer, cast(u8) layer.use_bias);
        io.binary_write_byte(^writer, cast(u8) layer.activation.id);
        
        // TODO(Brendan Hansen): These are so slow because of the enormous
        // amount of writes that have to happen. I would like to write them
        // in bulk, but the problem is that the data that needs to be stored
        // is not contiguous in memory because of AOS style of variables. If
        // that could be changed to a SOA style, the saving and loading process
        // here could be made much much faster.
        if layer.use_bias {
            for ^bias: layer.biases {
                io.binary_write(^writer, f32, ^bias.value);
            }
        }
        
        for ^weight: layer.weights {
            io.binary_write(^writer, f32, ^weight.value);
        }
    }
}

neural_net_load :: (filename: str) -> NeuralNet {
    err, input_file := io.open(filename, io.OpenMode.Read);
    assert(err == io.Error.None, "Failed to open neural net save file for reading.");
    defer io.stream_close(^input_file);

    reader := io.binary_reader_make(^input_file);

    magic_number := io.binary_read(^reader, i32);
    assert(magic_number == Onyx_NN_Magic_Number, "Magic number did not match!");

    num_layers := io.binary_read(^reader, i32);

    nn : NeuralNet;
    nn.init(^nn, num_layers);

    layer_allocator := alloc.arena.make_allocator(^nn.layer_arena);
    prev_layer_size := 0;

    for l: num_layers {
        layer_size := io.binary_read(^reader, i32);
        is_input   := cast(bool) io.binary_read_byte(^reader);

        Layer.init(^nn.layers[l], layer_size, prev_layer_size, allocator = layer_allocator);
        if !is_input {
            nn.layers[l].use_bias = cast(bool) io.binary_read_byte(^reader);

            activation_id := cast(ActivationFunctionID) io.binary_read_byte(^reader);
            nn.layers[l].activation = activation_function_from_id(activation_id);

            if nn.layers[l].use_bias {
                for i: layer_size {
                    nn.layers[l].biases[i].value = io.binary_read(^reader, f32);
                }
            }

            for w: layer_size {
                for ww: prev_layer_size {
                    nn.layers[l].weights[w * prev_layer_size + ww].value = io.binary_read(^reader, f32);
                }
            }
        }

        prev_layer_size = layer_size;
    }

    return nn;
}






//
// Activation functions
//     The activation functions that are currently implemented are:
//         - Sigmoid
//         - Hyperbolic Tangent
//         - ReLU
//


// Solely used for serializing. Need a way to store the activation
// functions uniquely and reproducibly.
ActivationFunctionID :: enum (u8) {
    Invalid            :: 0x00;
    Sigmoid            :: 0x01;
    Hyperbolic_Tangent :: 0x02;
    ReLU               :: 0x03;
}

activation_function_from_id :: (id: ActivationFunctionID) -> ActivationFunction {
    use ActivationFunctionID;
    
    switch id {
        case Sigmoid            do return sigmoid_activation;
        case Hyperbolic_Tangent do return tanh_activation;
        case ReLU               do return relu_activation;

        case #default do return ActivationFunction.{
            ActivationFunctionID.Invalid,
            null_proc, null_proc,
        };
    }
}

ActivationFunction :: struct {
    id       : ActivationFunctionID;
    forward  : (x : f32)         -> f32;
    backward : (fx: f32, x: f32) -> f32;
}


sigmoid_activation := ActivationFunction.{
    ActivationFunctionID.Sigmoid,
    sigmoid, sigmoid_prime
}

sigmoid :: (x: f32) -> f32 {
    ex := math.exp(x);
    return ex / (1 + ex);
}

sigmoid_prime :: (sx: f32, _: f32) -> f32 {
    // This is defined in terms of the sigmoid of x
    // sigma'(x) = sigma(x) * (1 - sigma(x))
    return sx * (1 - sx);
}


tanh_activation := ActivationFunction.{
    ActivationFunctionID.Hyperbolic_Tangent,
    tanh, tanh_prime
}

tanh :: (x: f32) -> f32 {
    ex  := math.exp(x);
    emx := math.exp(-x);
    return (ex - emx) / (ex + emx);
}

tanh_prime :: (_: f32, x: f32) -> f32 {
    ex  := math.exp(x);
    emx := math.exp(-x);
    s   := emx + ex;
    return 4 / (s * s);
}


relu_activation := ActivationFunction.{
    ActivationFunctionID.ReLU,
    relu, relu_prime
}

relu :: (x: f32) -> f32 {
    if x < 0 do return 0;
    return x;
}

relu_prime :: (rx: f32, _: f32) -> f32 {
    if rx > 0 do return 1;
    return 0;
}


//
// Criteria
//     Currently, these are the implemented criteria:
//         - MSE (Mean Squared Error)
//         - MAE (Mean Absolute Error)
//         - BCE (Binary Cross Entropy)
//

Criterion :: struct {
    compute_loss   : (predictions: [] f32, expected: [] f32) -> f32;
    
    // `deltas` is an out parameter that holds the derivatives.
    compute_deltas : (deltas: [] f32, predictions: [] f32, expected: [] f32) -> void;
}

mean_squared_error := Criterion.{
    compute_loss = (prediction: [] f32, expected: [] f32) -> f32 {
        assert(prediction.count == expected.count, "Expected output does not have the same size as predictions.");
                
        squared_sum: f32 = 0;
        for i: expected.count {
            diff := prediction[i] - expected[i];
            squared_sum += diff * diff;
        }
        
        loss := squared_sum / ~~expected.count;
        return loss;
    },
    
    compute_deltas = (deltas: [] f32, predictions: [] f32, expected: [] f32) {
        for j: deltas.count {
            deltas[j] = 2 * (expected[j] - predictions[j]) / ~~expected.count;
        }
    },
}

mean_absolute_error := Criterion.{
    compute_loss = (prediction: [] f32, expected: [] f32) -> f32 {
        assert(prediction.count == expected.count, "Expected output does not have the same size as predictions.");
        
        squared_sum: f32 = 0;
        for i: expected.count {
            diff := prediction[i] - expected[i];
            squared_sum += math.abs(diff);
        }
        
        loss := squared_sum / ~~expected.count;
        return loss;
    },
    
    compute_deltas = (deltas: [] f32, predictions: [] f32, expected: [] f32) {
        for j: deltas.count {
            deltas[j] = 1.0f;
            if expected[j] < predictions[j] do deltas[j] = -1.0f;
            
            // TODO(Brendan Hansen):
            // Technically, this division should be here, but it doesn't appear to be helping the gradient descent.
            deltas[j] /= cast(f32) expected.count;
        }
    },
}



//
// DataLoader (move this to somewhere else)
//
// Very basic datastructure that represents something you can load data out of.
// Specifically, an input and output at a particular index.
//

DataLoader :: struct (Sample_Type: type_expr) {
    vtable : ^DataLoader_Functions(Sample_Type);
}

DataLoader_Functions :: struct (Sample_Type: type_expr) {
    get_count : (^DataLoader(Sample_Type)) -> u32;
    get_item  : (^DataLoader(Sample_Type), index: u32, sample: ^Sample_Type) -> bool;
}

dataloader_get_count :: (use data: ^DataLoader($Sample_Type)) -> u32 {
    if vtable == null do return 0;
    if vtable.get_count == null_proc do return 0;
    
    return vtable.get_count(data);
}

dataloader_get_item :: (use data: ^DataLoader($Sample_Type), index: u32, sample: ^Sample_Type) -> bool {
    if vtable == null do return false;
    if vtable.get_item == null_proc do return false;
    
    return vtable.get_item(data, index, sample);
}


//
// Optimizers
//

Optimizer :: struct {
    vtable    : ^Optimizer_Functions;
    network   : ^NeuralNet;
    
    // TODO(Brendan Hansen): Make these fixed size slices?
    // This would require know the exact parameter count for the network.
    
    // NOTE(Brendan Hansen): Used to store standalone variables that need to be updated.
    variables : [..] ^Variable;
    
    // NOTE(Brendan Hansen): Used to store contigiously allocated variables that need to be updated.
    // This prevents having a LOT of variables in the variables array.
    variable_arrays : [..] ^[] Variable;
}

Optimizer_Functions :: struct {
    step : (optimizer: ^Optimizer, scale: f32) -> void;
}

optimizer_init :: (use optim: ^Optimizer, nn: ^NeuralNet, allocator := context.allocator) {
    network = nn;

    #context_scope {
        context.allocator = allocator;

        variables       = array.make(#type ^Variable);
        variable_arrays = array.make(#type ^[] Variable);
    }
}

optimizer_step :: (use optim: ^Optimizer, scale: f32 = 1) {
    if vtable == null do return;
    if vtable.step == null_proc do return;

    vtable.step(optim, scale);
}

optimizer_zero_gradient :: (use optim: ^Optimizer) {
    for variable: variables {
        variable.delta = 0;
    }

    for variable_array: variable_arrays {
        for ^variable: *variable_array {
            variable.delta = 0;
        }
    }
}



SGD_Optimizer :: struct {
    use base : Optimizer;
    
    learning_rate : f32;
}

sgd_optimizer_vtable := Optimizer_Functions.{
    step = sgd_optimizer_step,
};

sgd_optimizer_create :: (nn: ^NeuralNet, learning_rate := 0.01f, allocator := context.allocator) -> SGD_Optimizer {
    sgd : SGD_Optimizer;
    sgd.vtable = ^sgd_optimizer_vtable;
    optimizer_init(^sgd, nn, allocator);

    sgd.learning_rate = learning_rate;

    return sgd;
}

sgd_optimizer_step :: (use optimizer: ^SGD_Optimizer, scale: f32) {
    alpha := scale * learning_rate;

    for variable: variables {
        variable.value += variable.delta * alpha;
    }

    for variable_array: variable_arrays {
        for ^variable: *variable_array {
            variable.value += variable.delta * alpha;
        }
    }
}