#load "core/std/wasi"

#load_path "src"
#load "neuralnet"

use package core

MNIST_Data :: struct {
    images : io.FileStream;
    labels : io.FileStream;
}

mnist_data_make :: (image_path := "data/train-images-idx3-ubyte", label_path := "data/train-labels-idx1-ubyte") -> MNIST_Data {
    mnist_data: MNIST_Data;

    err : io.Error;
    err, mnist_data.images = io.open(image_path);
    assert(err == io.Error.None, "There was an error loading the image file");

    err, mnist_data.labels = io.open(label_path);
    assert(err == io.Error.None, "There was an error loading the label file");

    return mnist_data;
}

mnist_data_close :: (use mnist_data: ^MNIST_Data) {
    io.stream_close(^images);
    io.stream_close(^labels);
}

load_example :: (use mnist_data: ^MNIST_Data, example: u32, out: [784] u8) -> u32 {
    location := 16 + example * 784;
    _, bytes_read := io.stream_read_at(^images, location, ~~ out);

    assert(bytes_read == 784, "Incorrect number of bytes read.");

    location = 8 + example;
    label_buf : [1] u8;
    _, bytes_read = io.stream_read_at(^labels, location, ~~ label_buf);
    return ~~ label_buf[0];
}

stocastic_gradient_descent :: (nn: ^NeuralNet, mnist_data: ^MNIST_Data, training_examples := 50000) {
    example : [784] u8;
    expected := f32.[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ];
    input := memory.make_slice(f32, 784);
    defer cfree(input.data);

    for i: 10 {
        for ex: training_examples {
            label := load_example(mnist_data, ex, example);
            expected[label] = 1.0f;
            defer expected[label] = 0.0f;

            // CLEANUP: The double cast that is necessary here is gross.
            for i: input.count do input[i] = (cast(f32) cast(u32) example[i]) / 255;

            neural_net_forward(nn, ~~ input);
            neural_net_backward(nn, ~~ expected);

            if ex % 100 == 0 {
                print_colored_array :: (arr: [] $T, color_idx: i32, color_code := 94) {
                    for i: arr.count {
                        if i == color_idx {
                            printf("\x1b[%im", color_code);
                            print(arr[i]);
                            print("\x1b[0m ");
                        } else {
                            print(arr[i]);
                            print(" ");
                        }
                    }
                    print("\n");
                }

                output := neural_net_get_output(nn);
                prediction := neural_net_get_prediction(nn);

                color := 94;
                if prediction != label do color = 91;

                print_colored_array(cast([] f32) expected, label, color);
                print_colored_array(output, prediction, color);

                loss := neural_net_loss(nn, ~~ expected);
                printf("MSE loss: %f\n", cast(f32) loss);

                if ex % 10000 == 0 {
                    println("Saving neural network...");
                    neural_net_save(nn, "data/test_1.nn");
                }
            }
        }
    }

}

main :: (args: [] cstr) {
    // Enables a logging allocator to print every allocation
    // main_allocator := context.allocator;
    // context.allocator = alloc.log.logging_allocator(^main_allocator);

    nn := neural_net_load("data/test_1.nn");
    // nn := make_neural_net(28 * 28, 512, 256, 100, 10);
    defer neural_net_free(^nn);

    random.set_seed(5234);

    mnist_data := mnist_data_make();
    defer mnist_data_close(^mnist_data);

    stocastic_gradient_descent(^nn, ^mnist_data);
}